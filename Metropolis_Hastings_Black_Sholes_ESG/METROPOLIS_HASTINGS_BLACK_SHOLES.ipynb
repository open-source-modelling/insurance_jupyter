{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed543bc",
   "metadata": {},
   "source": [
    "# ESG likelihood test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f11650",
   "metadata": {},
   "source": [
    "## Executive summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7676897",
   "metadata": {},
   "source": [
    "The main objective of this script is to demonstrate a statistical test that looks at the most likely parameterisation $\\theta$ that was used to generate a specific stochastic scenario sample. \n",
    "\n",
    "This test uses the statistical assumption that the parameterisation that was used to generate the sample is the one that generates the highest likelihood $\\theta$ when applied to the sample.\n",
    "\n",
    "#### Extension\n",
    "When the ESG has a simple-enough form (such that the likelihood function is well-defined and differentiable) this can be done using a classical maximum-likelihood test. The proposed approach extends this test to cases where the maximum likelihood test cannot be applied, but it is possible to calculate if a sample is more/less likely to be generated from a given parameterisation $\\theta`$ than another parameterisation $\\theta^*$.\n",
    "\n",
    "#### Limitation\n",
    "There are at least 5 major limitations to this test:\n",
    " - The stochastic process that was used to generate the sample must be known and is assumed to be true\n",
    " - The likelihood of the sample coming from a sample needs to be known up to a constant\n",
    " - The statistical nature of the test means that the most likely parameter is not necessarily the right one (Only with high probability)\n",
    " - Because this is a Bayesian technique, it requires to specify a prior knowledge  which can be subjective.\n",
    " - The computational need scales quadratically with desired accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a27ccef",
   "metadata": {},
   "source": [
    "## Description of methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7f19e7",
   "metadata": {},
   "source": [
    "Assuming a economic stochastic generator `G` with a parameterisation vector $\\theta = [\\theta_1,  \\theta_2, ..., \\theta_n]$ was used to generate a sample set $S = [s_1, s_2, \\dots, s_m]$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed46cb",
   "metadata": {},
   "source": [
    "Assuming the user only knows the form of the generator `G` and the sample `S`. The challenge is to determine, what specific values of $\\theta_1, \\theta_2, \\dots, \\theta_n $ were used in generating the sample $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c14b5",
   "metadata": {},
   "source": [
    "For convenience, we will denote the \"real\" parameterisation that generator G used as $\\theta^{TRUE}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc34ad",
   "metadata": {},
   "source": [
    "Within the statistical inference field, a popular test is to find set of parameters that maximise the likelihood function: \n",
    "\n",
    "$$\\theta^{ML} = \\max_{\\theta} \\big(p(S | \\theta)\\big) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e43d32",
   "metadata": {},
   "source": [
    "#### Different ways to calculate maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ee113f",
   "metadata": {},
   "source": [
    "Computationally the fastest solution to this challenge is to derive a closed form equation of the joint likelihood of the samples, calculate the derivatives of the likelihood and thus obtain the global maximum candidates and finally the global maximum $\\theta^{ML}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf9160",
   "metadata": {},
   "source": [
    "On the other spectrum, one of the slower approaches, is to use a \"brute force\" method and generate random guesses of $\\theta$, calculating the $p(S | \\theta)$ and hoping that the largest \"guess\" is the global maximum. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbae5b1",
   "metadata": {},
   "source": [
    "The proposed approach is somewhere in the middle, where a more sophisticated way of generating potential $\\theta$-s is used. This empirical sampling is known as the \"Metropolis Hastings\" algorithm (Markov Chain Monte Carlo method that constructs a Markov chain whose stationary distribution converges to the target distribution).\n",
    "\n",
    "[Metropolis Hastings](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c082c2",
   "metadata": {},
   "source": [
    "The objective is to find:\n",
    "\n",
    "$$ \\theta^{ML} = \\max_{\\theta}\\big( \\pi(\\theta | S)\\big) $$\n",
    "\n",
    "In some models, most joint likelihood functions are hard to differentiate. The likelihood can be further written as:\n",
    "\n",
    "$$ \\pi(\\theta | S) = \\frac{\\pi(\\theta) p(S |\\theta)}{p(S)} ∝ \\pi(\\theta) p(S |\\theta) $$\n",
    "\n",
    "Calculating the likelihood $p(S |\\theta)$  is hard and many times (especially when estimating multiparameter models), calculating the normalizing constant $p(S)$ in multidimensional distributions is even harder.\n",
    "\n",
    "Where:\n",
    "- $\\pi(\\theta | S) \\dots$ Likelihood of diferent parameterizations being used to generate the sample\n",
    "- $\\pi(\\theta)\\dots$ Prior belief about what parameters could have been used\n",
    "- $p(S |\\theta)\\dots$ Probability of the observed sample coming from the generator `G` with a parameterisation $\\theta$\n",
    "- $p(S)\\dots$ normalizing factor (Unconditional probability of the sample)\n",
    "\n",
    "\n",
    "Using MH mitigates both issues: \n",
    " - It removes the need for the well-deffined derivative by sampling from an empirical distribution \n",
    " - it does not need to calculate the normalizing constant by only comparing two subsequent samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1431299e",
   "metadata": {},
   "source": [
    "The MH algorithm uses a Markov chain that asymptotically converges towards the target distribution $ \\pi(\\theta | S) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37cd9d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd4e26",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Example using Black Sholes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab457710",
   "metadata": {},
   "source": [
    "[Black–Scholes–Merton model](https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model) is a mathematical model for the dynamics of the stock market. This model assumes that the price of the underlying asset follows a [Geometric Brownian motion](https://en.wikipedia.org/wiki/Geometric_Brownian_motion). \n",
    "\n",
    "That is, the underlying asset follows the process:\n",
    "\n",
    "$$ dS(t) = \\mu S(t) + \\sigma S(t) dW(t) $$\n",
    "\n",
    "\n",
    "or its integral form:\n",
    "\n",
    "$$ S(t) = S(0) + \\int_0^t \\mu S(s) ds + \\int_0^t \\sigma S(s) dW(s) $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b380f",
   "metadata": {},
   "source": [
    "This differential equation has a unique and stable solution:\n",
    "\n",
    "$$ S(t) = S(0) e^{(\\mu - \\frac{\\sigma^2}{2})t + \\sigma W(t)} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b765c36d",
   "metadata": {},
   "source": [
    "In practice, the simulation is not continuous. For two subsequent time points $t_k$ and $t_{k-1}$, the following equation holds:\n",
    "\n",
    "$$ S(t_k) = S(t_{k-1}) e^{ (\\mu - \\frac{\\sigma^2}{2})(t_k - t_{k-1}) + \\sigma (W(t_k) - W(t_{k-1}))} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72feef23",
   "metadata": {},
   "source": [
    "### Log Likelihood derivation\n",
    "\n",
    "By taking the logarithm of both sides and rearranging the terms, the equation transforms:\n",
    "\n",
    "$$ ln(S(t_k)) - ln(S(t_{k-1})) = (\\mu - \\frac{\\sigma^2}{2})(t_k - t_{k-1}) + \\sigma \\big(W(t_k) - W(t_{k-1})\\big) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6920ecf",
   "metadata": {},
   "source": [
    "From the equation above, the distribution of increments written:\n",
    "\n",
    "$$ ln(S(t_k)) - ln(S(t_{k-1})) \\stackrel{d}{\\sim} N\\big((\\mu - \\frac{\\sigma^2}{2})(t_k - t_{k-1}), \\sigma (t_k - t_{k-1})\\big) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d2301",
   "metadata": {},
   "source": [
    "### Black-Sholes implementation from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d5c7408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "de5e6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_Black_Scholes(S0, mu, sigma, T, dt) -> pd.DataFrame:\n",
    "    # SIMULATE_BLACK_SHOLES calculates a temporal series of stock prices using\n",
    "    # the Black Scholes log normal model and the generated Brownian motion\n",
    "    # stock_price_simulation = simulate_Black_Scholes(S0, mu, sigma, T, dt, rho)\n",
    "    #\n",
    "    # Arguments:\n",
    "    #   S0    = integer, specifying the initial value of the underlying asset\n",
    "    #   mu    = float, specifying the drift rate of the underlying asset \n",
    "    #   sigma = float, standard deviation of the underlying asset's return\n",
    "    #   T     = integer, specifying the maximum modelling time. ex. if T = 2 \n",
    "    #              then modelling time will run from 0 to 2\n",
    "    #   dt    = float, specifying the length of each subinterval. ex. dt=10, \n",
    "    #              then there will be 10 intervals of length 0.1 between two \n",
    "    #              integers of modelling time \n",
    "    #   rho   = float, specifying the correlation coefficient of the Brownian \n",
    "    #           motion. ex. rho = 0.4 means that two \n",
    "    #\n",
    "    # Returns:\n",
    "    #   stock_price_simulation = N x 2 pandas DataFrame where index is \n",
    "    #               modelling time and values are a realisation of the \n",
    "    #               underlying's price\n",
    "    #\n",
    "    # Example:\n",
    "    #   Model the price of a stock which is worth today 100. \n",
    "    #        The market has a future annualized risk-free rate of 5% and an \n",
    "    #        annualized volatility of 30%. \n",
    "    #        The user is interested in a price projection for the next 10 years\n",
    "    #        in increments of 6 months (0.5 years)\n",
    "    #\n",
    "    #   import pandas as pd\n",
    "    #   import numpy as np\n",
    "    #   simulate_Black_Scholes(100, 0.05, 0.3, 10, 0.5)   \n",
    "    #   [out] = Time    Stock Price                \n",
    "    #       0.0    100.000000\n",
    "    #       0.5    131.721286\n",
    "    #       1.0    124.924654\n",
    "    #       1.5    209.302935\n",
    "    #       2.0    222.085955\n",
    "    #       2.5    208.085678\n",
    "    #       3.0    165.550253\n",
    "    #       3.5    239.512165\n",
    "    #       4.0    176.886669\n",
    "    #       4.5    148.687363\n",
    "    #       5.0    181.235262\n",
    "    #       5.5    164.280753\n",
    "    #       6.0    172.861576\n",
    "    #       6.5    170.698562\n",
    "    #       7.0    141.613940\n",
    "    #       7.5    121.070316\n",
    "    #       8.0    116.508183\n",
    "    #       8.5    104.524616\n",
    "    #       9.0    146.124924\n",
    "    #       9.5    202.368581\n",
    "    #       10.0   262.282989\n",
    "    # For more info; https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model\n",
    "   \n",
    "\n",
    "\n",
    "    # number of subintervals of length 1/dt between 0 and max modelling time T\n",
    "    N = int(T / dt) \n",
    "   \n",
    "    time, delta_t = np.linspace(0, T, num = N+1, retstep = True)\n",
    "    S = np.exp((mu - sigma ** 2 / 2) * dt + sigma * np.sqrt(dt)* \\\n",
    "               np.random.normal(0, 1 , size= N))\n",
    "    S = np.hstack([1, S])\n",
    "    dict = {'Time' : time, 'Stock Price' : S0* S.cumprod(axis=0)}\n",
    "\n",
    "    stock_price_simulation = pd.DataFrame.from_dict(data = dict)\n",
    "    stock_price_simulation.set_index('Time', inplace = True)\n",
    "\n",
    "    return stock_price_simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3df4c",
   "metadata": {},
   "source": [
    "## Log likelihood\n",
    "\n",
    "The logarithmic increments follow a normal distribution. For convenience, the increment between $t_k$ and $t_{k-1}$ is defined as $x(t_k) = ln(S(t_k)) - ln(S(t_{k-1}))$. The likelihood function of a single increment is:\n",
    "\n",
    "$$ f_\\theta (x(t_k)) = \\frac{1}{\\sigma \\sqrt{2 \\pi (t_k - t_{k-1})}} e^{\\frac{[x(t_k) - (\\mu - \\frac{\\sigma^2}{2})(t_k - t_{k-1})]^2}{2\\sigma^2 (t_k - t_{k-1})}}  $$\n",
    "\n",
    "\n",
    "The log likelihood for the entire scenario is therefore:\n",
    "\n",
    "$$ L(\\theta) = \\sum_{k=1}^n ln(f_\\theta(x(t_k)))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ca4fe",
   "metadata": {},
   "source": [
    "$$ L(\\theta) = \\sum_{k=1}^n ln\\big(\\frac{1}{\\sigma \\sqrt{2 \\pi (t_k - t_{k-1})}} e^{-\\frac{\\big[x(t_k) - (\\mu - \\frac{\\sigma^2}{2})(t_k - t_{k-1})\\big]^2}{2\\sigma^2 (t_k - t_{k-1})}}\\big) = $$\n",
    "\n",
    "$$= \\sum_{k=1}^n -ln(\\sigma) -\\frac{1}{2}ln(2 \\pi (t_k - t_{k-1})) -\\frac{\\big[x(t_k) - (\\mu - \\frac{\\sigma^2}{2})(t_k - t_{k-1})\\big]^2}{2\\sigma^2 (t_k - t_{k-1})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b2c9b",
   "metadata": {},
   "source": [
    "$$= -n ln(\\sigma) -\\frac{n}{2}ln(2 \\pi)  -\\frac{1}{2}\\sum_{k=1}^n  ln(t_k - t_{k-1}) -\\sum_{k=1}^n\\frac{\\big[x(t_k) - (\\mu - \\frac{\\sigma^2}{2})(t_k - t_{k-1})\\big]^2}{2\\sigma^2 (t_k - t_{k-1})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf0232b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eedcef",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e6bd94",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb214a",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec184f73",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593171d",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c46a8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042bfe7",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e5a01b",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a2da9e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee8df5e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953a3b72",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4cea7",
   "metadata": {},
   "source": [
    "# ESG simulation\n",
    "\n",
    "For this example, the code generates 1000 scenarios from the Black-Sholes-Merton model denoted as `G`. Each scenario simulates 50 years in annual increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a425f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nScen = 1000\n",
    "nYear = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf86a99",
   "metadata": {},
   "source": [
    "BSM model takes 2 parameters. The average return $\\mu$ and the annual volatility $\\sigma$. This example uses dummy numbers roughly in line with the S&P return/volatility profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a70dbab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.106  \n",
    "sigma = 0.181 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ffe533ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_paths = pd.DataFrame(simulate_Black_Scholes(1, mu, sigma, nYear, 1).values,\n",
    "                            columns=[\"Scenario0\"])\n",
    "\n",
    "for iStep in range(1,nScen):\n",
    "    name = \"Scenario\"+ str(iStep)\n",
    "    sample = pd.DataFrame(simulate_Black_Scholes(1, mu, sigma, nYear, 1).values,\n",
    "                          columns=[name])\n",
    "    sample_paths = sample_paths.join(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38015f3",
   "metadata": {},
   "source": [
    "The set of scenarios has the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "140b2fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario0</th>\n",
       "      <th>Scenario1</th>\n",
       "      <th>Scenario2</th>\n",
       "      <th>Scenario3</th>\n",
       "      <th>Scenario4</th>\n",
       "      <th>Scenario5</th>\n",
       "      <th>Scenario6</th>\n",
       "      <th>Scenario7</th>\n",
       "      <th>Scenario8</th>\n",
       "      <th>Scenario9</th>\n",
       "      <th>...</th>\n",
       "      <th>Scenario990</th>\n",
       "      <th>Scenario991</th>\n",
       "      <th>Scenario992</th>\n",
       "      <th>Scenario993</th>\n",
       "      <th>Scenario994</th>\n",
       "      <th>Scenario995</th>\n",
       "      <th>Scenario996</th>\n",
       "      <th>Scenario997</th>\n",
       "      <th>Scenario998</th>\n",
       "      <th>Scenario999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.814988</td>\n",
       "      <td>0.990757</td>\n",
       "      <td>1.317606</td>\n",
       "      <td>1.474511</td>\n",
       "      <td>1.032422</td>\n",
       "      <td>0.799623</td>\n",
       "      <td>1.214793</td>\n",
       "      <td>1.292732</td>\n",
       "      <td>0.999146</td>\n",
       "      <td>1.211274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994004</td>\n",
       "      <td>1.401769</td>\n",
       "      <td>0.986074</td>\n",
       "      <td>1.021310</td>\n",
       "      <td>0.941567</td>\n",
       "      <td>0.905083</td>\n",
       "      <td>1.423185</td>\n",
       "      <td>0.979030</td>\n",
       "      <td>1.128341</td>\n",
       "      <td>1.278167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.016858</td>\n",
       "      <td>1.147728</td>\n",
       "      <td>1.320901</td>\n",
       "      <td>2.124760</td>\n",
       "      <td>0.715171</td>\n",
       "      <td>1.308006</td>\n",
       "      <td>1.408918</td>\n",
       "      <td>1.099190</td>\n",
       "      <td>1.445713</td>\n",
       "      <td>1.686652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.476581</td>\n",
       "      <td>1.982933</td>\n",
       "      <td>1.208096</td>\n",
       "      <td>1.118870</td>\n",
       "      <td>1.223915</td>\n",
       "      <td>0.763916</td>\n",
       "      <td>1.576963</td>\n",
       "      <td>0.800019</td>\n",
       "      <td>1.201193</td>\n",
       "      <td>1.483454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.956096</td>\n",
       "      <td>2.015158</td>\n",
       "      <td>1.612116</td>\n",
       "      <td>2.859219</td>\n",
       "      <td>0.740632</td>\n",
       "      <td>1.049028</td>\n",
       "      <td>1.263342</td>\n",
       "      <td>1.245121</td>\n",
       "      <td>1.881235</td>\n",
       "      <td>1.665309</td>\n",
       "      <td>...</td>\n",
       "      <td>1.848495</td>\n",
       "      <td>2.901593</td>\n",
       "      <td>1.678797</td>\n",
       "      <td>1.374564</td>\n",
       "      <td>1.132531</td>\n",
       "      <td>0.778640</td>\n",
       "      <td>1.717440</td>\n",
       "      <td>0.955571</td>\n",
       "      <td>1.593628</td>\n",
       "      <td>1.676466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.151063</td>\n",
       "      <td>2.057287</td>\n",
       "      <td>1.705073</td>\n",
       "      <td>3.527424</td>\n",
       "      <td>0.876255</td>\n",
       "      <td>1.037175</td>\n",
       "      <td>1.770545</td>\n",
       "      <td>1.253611</td>\n",
       "      <td>2.039554</td>\n",
       "      <td>1.500448</td>\n",
       "      <td>...</td>\n",
       "      <td>2.180595</td>\n",
       "      <td>2.574402</td>\n",
       "      <td>1.913027</td>\n",
       "      <td>1.512310</td>\n",
       "      <td>1.306278</td>\n",
       "      <td>0.969505</td>\n",
       "      <td>1.512344</td>\n",
       "      <td>0.948250</td>\n",
       "      <td>1.623320</td>\n",
       "      <td>1.455495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario0  Scenario1  Scenario2  Scenario3  Scenario4  Scenario5  \\\n",
       "0   1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "1   0.814988   0.990757   1.317606   1.474511   1.032422   0.799623   \n",
       "2   1.016858   1.147728   1.320901   2.124760   0.715171   1.308006   \n",
       "3   0.956096   2.015158   1.612116   2.859219   0.740632   1.049028   \n",
       "4   1.151063   2.057287   1.705073   3.527424   0.876255   1.037175   \n",
       "\n",
       "   Scenario6  Scenario7  Scenario8  Scenario9  ...  Scenario990  Scenario991  \\\n",
       "0   1.000000   1.000000   1.000000   1.000000  ...     1.000000     1.000000   \n",
       "1   1.214793   1.292732   0.999146   1.211274  ...     0.994004     1.401769   \n",
       "2   1.408918   1.099190   1.445713   1.686652  ...     1.476581     1.982933   \n",
       "3   1.263342   1.245121   1.881235   1.665309  ...     1.848495     2.901593   \n",
       "4   1.770545   1.253611   2.039554   1.500448  ...     2.180595     2.574402   \n",
       "\n",
       "   Scenario992  Scenario993  Scenario994  Scenario995  Scenario996  \\\n",
       "0     1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "1     0.986074     1.021310     0.941567     0.905083     1.423185   \n",
       "2     1.208096     1.118870     1.223915     0.763916     1.576963   \n",
       "3     1.678797     1.374564     1.132531     0.778640     1.717440   \n",
       "4     1.913027     1.512310     1.306278     0.969505     1.512344   \n",
       "\n",
       "   Scenario997  Scenario998  Scenario999  \n",
       "0     1.000000     1.000000     1.000000  \n",
       "1     0.979030     1.128341     1.278167  \n",
       "2     0.800019     1.201193     1.483454  \n",
       "3     0.955571     1.593628     1.676466  \n",
       "4     0.948250     1.623320     1.455495  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_paths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8cc07",
   "metadata": {},
   "source": [
    "The scenarios are converted into logarithmic annual returns\n",
    "\n",
    "$$ \\log(S_{t+1}) - \\log(S_{t})  $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c273959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.log(sample_paths)\n",
    "data = data1.diff()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d734e064",
   "metadata": {},
   "source": [
    "# Metropolis Hastings algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087eab47",
   "metadata": {},
   "source": [
    "To ensure that the algorithm has converged to a solution, a sufficiently large number of steps needs to be selected. In this example, 500,000 runs are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95de8d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSteps = 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4482b76d",
   "metadata": {},
   "source": [
    "A random starting point is selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56030ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting position\n",
    "muhatminus1 = 0.02\n",
    "sigmahatminus1 = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd50b11d",
   "metadata": {},
   "source": [
    "To neutralize the effect of the starting point which can be arbitrary, a significant number of first steps is discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a908558",
   "metadata": {},
   "outputs": [],
   "source": [
    "discarded_sample_percentage = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7be38",
   "metadata": {},
   "source": [
    "The prior distribution is assumed to be independent normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "168358c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior distribution\n",
    "prior_mean_1 = 0.2\n",
    "prior_mean_2 = 0.3\n",
    "prior_sd_1 = np.sqrt(0.5)\n",
    "prior_sd_2 = np.sqrt(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c1f938",
   "metadata": {},
   "source": [
    "The proposal distribution (A way to generate new proposed $\\theta$-s) is assumed to be normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7a7d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposal distribution\n",
    "proposal_sd_1 = np.sqrt(1.5)\n",
    "proposal_sd_2 = np.sqrt(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29813f4d",
   "metadata": {},
   "source": [
    "The log likelihood function of the prior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6dbf4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_lf(mu,sigma,x):\n",
    "# Log likelihood of the normal distribution\n",
    "    n = 1\n",
    "    out = -n/2*np.log(2*np.pi)-n*np.log(sigma)-1/2 * 1/np.power(sigma,2)*(x-mu)**2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b884a",
   "metadata": {},
   "source": [
    "The log likelihood function for the BSM increment sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bd72ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnorm_lf(mu,sigma,x):\n",
    "# Log likelihood of a vector from the normal distribution\n",
    "    n = x.size   \n",
    "    out = -n/2 * np.log(2*np.pi)-n*np.log(sigma) -1/(2 * np.power(sigma,2)) * \\\n",
    "        np.sum((x-(mu-sigma**2 /2))**2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8611ac",
   "metadata": {},
   "source": [
    "## Run of the Metropolis Hastings algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93892bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structure with accepted parameter values\n",
    "result = np.zeros((NSteps,2))\n",
    "\n",
    "# Acceptance vector presampled for higher preformance\n",
    "u = np.log(np.random.uniform(0,1,NSteps))\n",
    "\n",
    "for step in range(0,NSteps):\n",
    "    muhat = np.random.normal(muhatminus1,proposal_sd_1)\n",
    "    sigmahat = np.random.normal(sigmahatminus1,proposal_sd_2)\n",
    "\n",
    "    if sigmahat<0:\n",
    "        sigmahat = -sigmahat\n",
    "\n",
    "    poslike = lnorm_lf(muhat,sigmahat,data.values)\n",
    "    neglike = lnorm_lf(muhatminus1,sigmahatminus1,data.values)\n",
    "        \n",
    "    poslognorm = poslike + norm_lf(prior_mean_1,prior_sd_1,muhat)+ \\\n",
    "        norm_lf(prior_mean_2,prior_sd_2,sigmahat)\n",
    "    neglognorm = neglike + norm_lf(prior_mean_1,prior_sd_1,muhatminus1) + \\\n",
    "        norm_lf(prior_mean_2,prior_sd_2,sigmahatminus1)    \n",
    "    \n",
    "    alpha = poslognorm - neglognorm\n",
    "\n",
    "    if u[step]>alpha:\n",
    "        result[step,:] = [muhatminus1, sigmahatminus1]\n",
    "\n",
    "    else:\n",
    "        result[step,:] = [muhat, sigmahat]\n",
    "        muhatminus1 = muhat\n",
    "        sigmahatminus1 = sigmahat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b82c66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdResult = pd.DataFrame(result,columns = ['mu','sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1e9c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude initial samples to mitigate the effect of initial conditions\n",
    "RealStart = round(nScen*discarded_sample_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "141d588a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([145539.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0., 107309.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,  14680., 179998.,      0.,  31489.,      0.,      0.,\n",
       "             0.,      0.,      0.,      0.,      0.,      0.,      0.,\n",
       "             0.,  20485.]),\n",
       " array([0.17967575, 0.18007229, 0.18046882, 0.18086536, 0.1812619 ,\n",
       "        0.18165843, 0.18205497, 0.1824515 , 0.18284804, 0.18324458,\n",
       "        0.18364111, 0.18403765, 0.18443418, 0.18483072, 0.18522725,\n",
       "        0.18562379, 0.18602033, 0.18641686, 0.1868134 , 0.18720993,\n",
       "        0.18760647, 0.18800301, 0.18839954, 0.18879608, 0.18919261,\n",
       "        0.18958915, 0.18998569, 0.19038222, 0.19077876, 0.19117529,\n",
       "        0.19157183]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "axs[0].hist(pdResult['mu'][RealStart:], bins=30)\n",
    "axs[1].hist(pdResult['sigma'][RealStart:], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "632cbd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimatedParam = pdResult[RealStart:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a9644fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of mu differs from the real value by -0.7049989582275331 % \n"
     ]
    }
   ],
   "source": [
    "print('Estimation of mu differs from the real value by {0} % '\n",
    "      .format((mu-estimatedParam[\"mu\"])/mu*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a27d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation of sigma differs from the real value by -1.5777176379322104 % \n"
     ]
    }
   ],
   "source": [
    "print('Estimation of sigma differs from the real value by {0} % '\n",
    "      .format((sigma-estimatedParam[\"sigma\"])/sigma*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
